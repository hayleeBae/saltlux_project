{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\numpy\\utils.py:37: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  bool = onp.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_33008\\3551097968.py\", line 6, in <module>\n",
      "    import gluonnlp as nlp\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\gluonnlp\\__init__.py\", line 23, in <module>\n",
      "    from . import loss\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\gluonnlp\\loss\\__init__.py\", line 23, in <module>\n",
      "    from .activation_regularizer import *\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\gluonnlp\\loss\\activation_regularizer.py\", line 25, in <module>\n",
      "    from mxnet.gluon.loss import Loss\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\__init__.py\", line 33, in <module>\n",
      "    from . import contrib\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\contrib\\__init__.py\", line 30, in <module>\n",
      "    from . import text\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\contrib\\text\\__init__.py\", line 23, in <module>\n",
      "    from . import embedding\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\contrib\\text\\embedding.py\", line 36, in <module>\n",
      "    from ... import numpy as _mx_np\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\numpy\\__init__.py\", line 23, in <module>\n",
      "    from .multiarray import *  # pylint: disable=wildcard-import\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\numpy\\multiarray.py\", line 47, in <module>\n",
      "    from .utils import _get_np_op\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\mxnet\\numpy\\utils.py\", line 37, in <module>\n",
      "    bool = onp.bool\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\numpy\\__init__.py\", line 352, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# transforemers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "from kobert import get_pytorch_kobert_model\n",
    "from kobert_transformers import get_kobert_model, get_distilkobert_model, get_tokenizer\n",
    "\n",
    "# BERT 모델, Voca 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "# bertmodel = get_kobert_model()\n",
    "\n",
    "\n",
    "# GPU 사용\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사가정 모인 이비인후과 항상 만원이다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>좋아요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                content  sentiment\n",
       "0  사가정 모인 이비인후과 항상 만원이다          0\n",
       "1                   좋아요          1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드 -> 리뷰 텍스트에 대한 긍정인지 부정인지 학습에 필요하므로 name컬럼 drop\n",
    "Jungrang_reviews_sentiment = pd.read_excel('C:/Users/user/Desktop/saltlux_project/data/review_file_junrang.xlsx')\n",
    "reviews_sentiment = Jungrang_reviews_sentiment[['content', 'sentiment']]\n",
    "reviews_sentiment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = reviews_sentiment[['content']]\n",
    "y = reviews_sentiment['sentiment']\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 y를 하나의 데이터프레임으로 합치기\n",
    "dataset_train = pd.concat([X_train, y_train], axis=1)\n",
    "dataset_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bert모델에 넣을 데이터셋 생성 -> transformer형식으로 데이터셋 변경 -> nlp 라이브러리 대신 transformers 라이브러리의 토크나이저를 사용\n",
    "# class BERTDataset(Dataset):\n",
    "#     def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
    "#         transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "#         self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "#         self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "#     def __getitem__(self, i) :\n",
    "#         return (self.sentences[i] + (self.labels[i], ))\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return(len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 모델에 넣을 데이터셋 생성 -> transformer 형식으로 데이터셋 변경\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad = pad\n",
    "        self.pair = pair\n",
    "        self.sentences = [str(i[sent_idx]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) if not pd.isna(i[label_idx]) else 0 for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sentence = str(self.sentences[i])  # Ensure the sentence is a string\n",
    "        encoding = self.tokenizer(sentence, padding=self.pad, truncation=True, max_length=self.max_len, return_tensors='np', return_token_type_ids=False)\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'][0],\n",
    "            'attention_mask': encoding['attention_mask'][0],\n",
    "            'labels': np.int32(self.labels[i])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 세팅\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 토큰화\n",
    "# tokenizer = get_tokenizer()\n",
    "# tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "# 직접 불러오기\n",
    "# KoBERT 모델 및 토크나이저 불러오기\n",
    "from transformers import BertModel\n",
    "from kobert_transformers import get_tokenizer\n",
    "model_name = 'skt/kobert-base-v1' #'monologg/kobert'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "# tokenizer = get_tokenizer()\n",
    "\n",
    "# 토크나이저에 오류 발생 -> pip install protobuf 실행\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 y를 하나의 데이터프레임으로 합치기\n",
    "dataset_train = pd.concat([X_train, y_train], axis=1)\n",
    "dataset_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset_train[['content']]\n",
    "y_train = dataset_train['sentiment']\n",
    "\n",
    "tok = tokenizer\n",
    "\n",
    "# 데이터셋 생성\n",
    "data_train = BERTDataset(list(zip(X_train['content'], y_train)), 0, 1, tok, max_len, True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dataset_test[['content']]\n",
    "y_test = dataset_test['sentiment']\n",
    "\n",
    "# 데이터셋 생성\n",
    "data_test = BERTDataset(list(zip(X_test['content'], y_test)), 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert, hidden_size = 768, num_classes=2, dr_rate=None, params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "    \n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "        _, pooler = self.bert(input_ids=token_ids, token_type_ids=segment_ids.long(), attention_mask=attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\saltlux_project\\transformer\\torch\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x25d76088820>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
    "\n",
    "# optimizer, schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params':[p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay': 0.01},\n",
    "     {'params':[p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "# 정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X, Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length = valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        \n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc/(batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc/(batch_id+1)))\n",
    "\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length = valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc/(batch_id+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
