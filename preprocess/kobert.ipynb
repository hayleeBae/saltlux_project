{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 미포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_jungrang_ori = pd.read_csv('C:/Users/user/Desktop/saltlux_project/preprocess/JungrangTotal.csv', index_col=0)\n",
    "review_jungrang_ori = review_jungrang_ori[['name', 'nickname', 'content']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nickname</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365mc모인이비인후과의원</td>\n",
       "      <td>Wiseburge David</td>\n",
       "      <td>사가정 모인 이비인후과 항상 만원이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365mc모인이비인후과의원</td>\n",
       "      <td>Dk9</td>\n",
       "      <td>좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365mc모인이비인후과의원</td>\n",
       "      <td>귀한집딸z</td>\n",
       "      <td>좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365mc모인이비인후과의원</td>\n",
       "      <td>꽃길걷는중임</td>\n",
       "      <td>항상 친절한 진료 감사합니다~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365mc모인이비인후과의원</td>\n",
       "      <td>막둥</td>\n",
       "      <td>ㅇㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>효치과의원</td>\n",
       "      <td>fpvocalist</td>\n",
       "      <td>굳</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>효치과의원</td>\n",
       "      <td>소보루39</td>\n",
       "      <td>좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>효치과의원</td>\n",
       "      <td>1vvovv1</td>\n",
       "      <td>친절하십니다 과잉진료 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>효치과의원</td>\n",
       "      <td>버럭아저씨</td>\n",
       "      <td>친절해요..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>효치과의원</td>\n",
       "      <td>fpvocalist</td>\n",
       "      <td>좋아요~~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5975 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name         nickname               content\n",
       "0     365mc모인이비인후과의원  Wiseburge David  사가정 모인 이비인후과 항상 만원이다\n",
       "1     365mc모인이비인후과의원              Dk9                   좋아요\n",
       "2     365mc모인이비인후과의원            귀한집딸z                   좋아요\n",
       "3     365mc모인이비인후과의원           꽃길걷는중임     항상 친절한 진료 감사합니다~ \n",
       "4     365mc모인이비인후과의원               막둥                    ㅇㅇ\n",
       "...              ...              ...                   ...\n",
       "5970           효치과의원       fpvocalist                     굳\n",
       "5971           효치과의원            소보루39                   좋아요\n",
       "5972           효치과의원          1vvovv1        친절하십니다 과잉진료 없음\n",
       "5973           효치과의원            버럭아저씨                친절해요..\n",
       "5974           효치과의원       fpvocalist                 좋아요~~\n",
       "\n",
       "[5975 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_jungrang_ori['content'] = review_jungrang_ori['content'].str.replace('\\n', ' ')\n",
    "review_jungrang_ori = review_jungrang_ori.reset_index(drop=True)\n",
    "review_jungrang_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 사용\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gluonnlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\saltlux_project\\preprocess\\kobert.ipynb 셀 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/saltlux_project/preprocess/kobert.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch_kobert\u001b[39;00m \u001b[39mimport\u001b[39;00m get_kobert_model\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/saltlux_project/preprocess/kobert.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertModel\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/saltlux_project/preprocess/kobert.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert_hf\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkobert_tokenizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkobert_tokenizer\u001b[39;00m \u001b[39mimport\u001b[39;00m KoBERTTokenizer\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\saltlux_project\\preprocess\\kobert\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Copyright 2019 SK T-Brain Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m download, get_tokenizer\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch_kobert\u001b[39;00m \u001b[39mimport\u001b[39;00m get_pytorch_kobert_model\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmxnet_kobert\u001b[39;00m \u001b[39mimport\u001b[39;00m get_mxnet_kobert_model\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx_kobert\u001b[39;00m \u001b[39mimport\u001b[39;00m get_onnx_kobert_model\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\saltlux_project\\preprocess\\kobert\\pytorch_kobert.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertModel\n\u001b[1;32m---> 20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgluonnlp\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnlp\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkobert\u001b[39;00m \u001b[39mimport\u001b[39;00m download, get_tokenizer\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pytorch_kobert_model\u001b[39m(ctx\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, cachedir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.cache\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gluonnlp'"
     ]
    }
   ],
   "source": [
    "from kobert.pytorch_kobert import get_kobert_model\n",
    "from transformers import BertModel\n",
    "from kobert_hf.kobert_tokenizer.kobert_tokenizer import KoBERTTokenizer\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "import torch\n",
    "\n",
    "# 'content' 컬럼의 데이터를 리스트로 추출\n",
    "texts = review_jungrang_ori['content'].tolist()\n",
    "\n",
    "# KoBERT 모델 및 토크나이저 불러오기\n",
    "model_name = 'skt/kobert-base-v1'\n",
    "tokenizer = KoBERTTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "# 각 텍스트에 대해 확률 계산 및 결과 저장\n",
    "for text in texts:\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokens).logits\n",
    "\n",
    "    probs = softmax(logits, dim=1).squeeze().tolist()\n",
    "    result_str = f\"긍정 확률: {probs[1]:.2%}, 부정 확률: {probs[0]:.2%}\"\n",
    "    results.append({'Text': text, 'Result': result_str})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results_df.to_csv('kobert_results_ori_prob.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gluonnlp==0.9.1\n",
    "pip install mxnet==1.6.0\n",
    "pip install boto3==1.15\n",
    "pip install onnxruntime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "\n",
    "# 'content' 컬럼의 데이터를 리스트로 추출\n",
    "texts = review_jungrang_ori['content'].tolist()\n",
    "\n",
    "# 모델과 토크나이저를 직접 다운로드\n",
    "model_name = 'monologg/kobert'\n",
    "model_path = 'monologg_kobert'\n",
    "tokenizer_path = 'monologg_kobert/tokenizer'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "# 각 텍스트에 대해 확률 계산 및 결과 저장\n",
    "for text in texts:\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokens).logits\n",
    "\n",
    "    probs = softmax(logits, dim=1).squeeze().tolist()\n",
    "    result_str = f\"긍정 확률: {probs[1]:.2%}, 부정 확률: {probs[0]:.2%}\"\n",
    "    results.append({'Text': text, 'Result': result_str})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results_df.to_csv('kobert_results_ori_prob.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, DistilBertModel\n",
    "from kobert_transformers import get_tokenizer\n",
    "\n",
    "# 'content' 컬럼의 데이터를 리스트로 추출\n",
    "texts = review_jungrang_ori['content'].tolist()\n",
    "\n",
    "# KoBERT 모델 및 토크나이저 불러오기\n",
    "model_name = 'skt/kobert-base-v1'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "# 임계값 설정\n",
    "threshold = 0.5\n",
    "\n",
    "# 각 텍스트에 대해 확률 계산 및 결과 저장\n",
    "for text in texts:\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        # 'last_hidden_state'를 사용하여 모델 출력 얻기\n",
    "        outputs = model(**tokens)\n",
    "    # 'last_hidden_state'에서 [CLS] 토큰에 해당하는 벡터 가져오기\n",
    "    cls_token_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    # 확률 계산 방법 적용 -> softmax\n",
    "    probs = softmax(cls_token_embedding, dim=1).squeeze().tolist()\n",
    "    result_str = f\"긍정 확률: {probs[1]:.2%}, 부정 확률: {probs[0]:.2%}\"\n",
    "    results.append({'Text': text, 'Result': result_str})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results_df.to_csv('kobert_results_ori_prob.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from kobert_transformers import get_tokenizer\n",
    "from torch.nn.functional import softmax\n",
    "import pandas as pd\n",
    "\n",
    "# 'content' 컬럼의 데이터를 리스트로 추출\n",
    "texts = review_jungrang_ori['content'].tolist()\n",
    "\n",
    "# KoBERT 모델 및 토크나이저 불러오기\n",
    "model_name = 'skt/kobert-base-v1'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "# 추가 분류 레이어 정의\n",
    "classifier = nn.Linear(768, 2)  # KoBERT의 hidden size는 768\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "# 임계값 설정\n",
    "threshold = 0.5\n",
    "\n",
    "# 각 텍스트에 대해 확률 계산 및 결과 저장\n",
    "for text in texts:\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        # 'last_hidden_state'를 사용하여 모델 출력 얻기\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    # 'last_hidden_state'에서 [CLS] 토큰에 해당하는 벡터 가져오기\n",
    "    cls_token_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    # 추가 분류 레이어를 통과시켜 로짓 계산\n",
    "    logits = classifier(cls_token_embedding)\n",
    "    \n",
    "    # 확률로 변환\n",
    "    probs = softmax(logits, dim=1).squeeze().tolist()\n",
    "    \n",
    "    # 임계값을 기준으로 긍정과 부정을 나눔\n",
    "    sentiment = \"긍정\" if probs[1] >= threshold else \"부정\"\n",
    "    results.append({'Text': text, 'Result': sentiment})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results_df.to_csv('kobert_results_ori_sentiment.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
